{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Double check Ramtin code.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hossein20s/AnExample/blob/master/Double_check_Ramtin_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikpWHuKwff72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SRC_DIR = 'src/ramtin-duplicate/'\n",
        "DATA_FILE = SRC_DIR + '/case01.csv'\n",
        "columns = [\"NBP (Mean)\", \"Minute Volume\"]\n",
        "\n",
        "window_size = 80\n",
        "batch_size = 64\n",
        "initial_epoch = 0\n",
        "epochs = 3\n",
        "model_name = '3conv1D' # 'ramtin2lstm64'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEMm3WcOfkNb",
        "colab_type": "text"
      },
      "source": [
        "# Initialize \n",
        "Using https://bit.ly/initnotebooksrc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKLbhjShfwT0",
        "colab_type": "code",
        "outputId": "d5be9495-9b04-4bc5-e1e3-d9fab4035bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        }
      },
      "source": [
        "!wget bit.ly/initnotebook -O init.ipynb\n",
        "%run init.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-18 00:39:51--  http://bit.ly/initnotebook\n",
            "Resolving bit.ly (bit.ly)... 18.232.107.46, 34.230.11.244, 54.158.109.168, ...\n",
            "Connecting to bit.ly (bit.ly)|18.232.107.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/hossein20s/notebook_snippets/master/InitializeNotebook.ipynb [following]\n",
            "--2019-06-18 00:39:51--  https://raw.githubusercontent.com/hossein20s/notebook_snippets/master/InitializeNotebook.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2163 (2.1K) [text/plain]\n",
            "Saving to: ‘init.ipynb’\n",
            "\n",
            "\rinit.ipynb            0%[                    ]       0  --.-KB/s               \rinit.ipynb          100%[===================>]   2.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-18 00:39:51 (32.6 MB/s) - ‘init.ipynb’ saved [2163/2163]\n",
            "\n",
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "ln: failed to create symbolic link 'models/models': Function not implemented\n",
            "ln: failed to create symbolic link 'data/data': Function not implemented\n",
            "ln: failed to create symbolic link 'checkpoints/checkpoints': Function not implemented\n",
            "ln: failed to create symbolic link 'src/src': Function not implemented\n",
            "ln: failed to create symbolic link 'notebooks/Colab Notebooks': Function not implemented\n",
            "fatal: destination path '/content/lib' already exists and is not an empty directory.\n",
            "Already up to date.\n",
            "save and load models from yaml and json files defined. Everything stored in folder  <built-in function dir>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb9HFUK7gOLf",
        "colab_type": "text"
      },
      "source": [
        "Get Ramtin code that has a great result\n",
        "After that you should have ![](https://lh3.googleusercontent.com/edWjvgXO1zbCh9R5DVksikXHi08lXfJHMZIk29NhGWIlMcntldJNrERnKeDhIX50o-KrP_VLyQ_TY-c41-ynJH0z8Py2T-Gs5u2Tl3eXlAbIQCuNZs8brWDY9ObkAFUSqltvUvBuibQ=w2400)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZsicOsOgV6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "gitconfig = \"git config --global user.email hossein@vitachain.app; git config --global user.name 'hossein20s' \"\n",
        "! git clone https://hossein20s:$PASSWORD@github.com/Rkeramati/ppg src/ramtin-ppg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIHz1sYCjV5H",
        "colab_type": "text"
      },
      "source": [
        "# Now copying Ramtin code\n",
        "Reusing pythons and I use my csv copy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zV34F7CvT0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JtPdJpavdbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "case_id = '01'\n",
        "data = pd.read_csv(DATA_FILE, #'data/case%s/uq_vsd_case%s_trenddata.csv'%(case_id, case_id),\\\n",
        "                               error_bad_lines=False, warn_bad_lines=False, index_col=False);\n",
        "data = data[[\"RelativeTimeMilliseconds\", \"NBP (Mean)\", \"Minute Volume\"]].dropna()\n",
        "data = (data - data.mean())/(data.max() - data.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDwu-qMtwTCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('src/ramtin-ppg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kebAltedwZHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gen import data_reader\n",
        "from rnn import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zfBo0lhwed9",
        "colab_type": "code",
        "outputId": "22c1a02b-206f-4b6d-db9d-403994453ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "NN = nn(80, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 18:45:14.863430 140181665015680 deprecation_wrapper.py:119] From src/ramtin-ppg/rnn.py:13: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0617 18:45:14.921113 140181665015680 deprecation.py:323] From src/ramtin-ppg/rnn.py:19: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0617 18:45:14.923524 140181665015680 deprecation.py:323] From src/ramtin-ppg/rnn.py:20: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0617 18:45:14.937983 140181665015680 deprecation.py:323] From src/ramtin-ppg/rnn.py:24: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "W0617 18:45:15.279471 140181665015680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0617 18:45:15.295441 140181665015680 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0617 18:45:20.290618 140181665015680 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0617 18:45:20.292171 140181665015680 deprecation.py:323] From src/ramtin-ppg/rnn.py:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0617 18:45:20.642896 140181665015680 deprecation_wrapper.py:119] From src/ramtin-ppg/rnn.py:35: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0617 18:45:20.725935 140181665015680 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpS0ELXlwoQx",
        "colab_type": "code",
        "outputId": "157b8911-fd12-4e3f-89e2-1ddb126f606b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "array_size = 80\n",
        "batchsize = 64\n",
        "max_epoch = 3\n",
        "total_loss = 0\n",
        "iteration = 0\n",
        "tf.reset_default_graph()\n",
        "\n",
        "train_loss = np.zeros(max_epoch)\n",
        "val_loss = np.zeros(max_epoch)\n",
        "\n",
        "reader = data_reader(data, l=array_size, batchsize=batchsize)\n",
        "NN = nn(array_size, 1)\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.initializers.global_variables())\n",
        "reader.reset()\n",
        "epoch = reader.get_epoch()\n",
        "\n",
        "while reader.get_epoch() < max_epoch:\n",
        "    X, Y = reader.get_next_train_batch()\n",
        "    loss_value = NN.train(X, Y, sess)\n",
        "    total_loss += loss_value\n",
        "    if epoch != reader.get_epoch():\n",
        "        X, Y = reader.get_val()\n",
        "        val_loss[epoch] = NN.compute_loss(X, Y, sess)\n",
        "        train_loss[epoch] = total_loss/iteration\n",
        "        if epoch%50 == 0:\n",
        "            print(\"Epoch: %d, Train Loss:%g, Val Loss:%g\"%\\\n",
        "                 (epoch, train_loss[epoch], val_loss[epoch]))\n",
        "        epoch+=1\n",
        "    iteration += 1\n",
        "\n",
        "plt.plot(np.arange(max_epoch), train_loss, label='train')\n",
        "plt.plot(np.arange(max_epoch), val_loss, label='validation')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Data passed should be normalized!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "src/ramtin-ppg/gen.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  df = df[[\"NBP (Mean)\", \"Minute Volume\"]].dropna().as_matrix()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Train Loss:0.0367574, Val Loss:0.0261283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e4789ea58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEBCAYAAABrF5JMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VOXZ8PHfmclk35MhJEAggXAD\nsiugouBetVatliJYqdpq9bWLrX3ftj6V4lZ9avu0tWJFRQUV3OVBRUCx7iKgbArcbIEACRBCyEq2\nmXn/mJNkEkJyJkxmJsn1/Xz4ZOac+5xc53Ay19zLuY/h8XgQQgghOmILdQBCCCG6B0kYQgghLJGE\nIYQQwhJJGEIIISyRhCGEEMISSRhCCCEskYQhhBDCEkkYQgghLJGEIYQQwhJJGEIIISyRhCGEEMKS\niFAHcIqigAlAEeAKcSxCCNFd2IFMYC1Qa3Wj7p4wJgCfhDoIIYTops4FPrVauLsnjCKA0tIq3G7/\nZ91NS4unpKQy4EGdKonLPxKX/8I1NonLP52Ny2YzSEmJA/Mz1KrunjBcAG63p1MJo3HbcCRx+Ufi\n8l+4xiZx+ecU4/KrKV86vYUQQlgiCUMIIYQl3b1JSgjRTXg8HkpLi6mrqwHabkY5fNiG2+0ObmAW\ndM+4DCIjo0lJcWIYRkB+nyQMIURQVFaWYRgGGRn9MYy2GzciImw0NITfB3N3jMvjcXPs2BEqK8tI\nSEgOyO+TJikhRFAcP15JQkLySZOFCCzDsJGQkMLx44Eb3SX/c0KIoHC7Xdjt0qgRTHZ7BG534O5p\n7rUJ45v8En7ywEpWfbUfVxi2TQrREwWqLV1YE+jz3WsTRnZGApnpcbz43nbufXYt2/aWhjokIUSQ\nzZ8/j/r6er+327ZtC/fe+8cuiCi89dqEkRgbyf0/O5s7vj+SmjoXf1m8nseXfENJWU2oQxNCBMmz\nzz7VZsJoaGhod7thw0bwpz890FVhha1e3aBoGAanqz6Myk1j+ZoCln2xl007j3D5mQO5dFI2kQ57\nqEMUQnSRv/3tvwG4/fabMQwbmZmZJCUlU1Cwl+rqap57bhH33vtHCgr20tBQT1ZWf/7wh9kkJiby\n9dfrmDv3n8yf/zxFRYX89Kc3cOWV17B69WfU1NTw+9/PZsyYsSE+wsDr1QmjUaTDzpWTc5g8MpNX\n/rOTJZ/m88mmIqZfMITTVeDGMAshmn22uYhPN7WcysgwwBOAGTjOGZ3J5FGZ7Za5667f8eabr/Lv\nfz9DbGwsDz44hx07tvPYY08SExMDwK9+9VuSk5OJiLDx+OOP8eKLC7j99l+csK+ysjJGjhzNz352\nBytXvssTTzzKv//9zKkfSJiRhOEjLSma268eyfl7S1n0/nYeX/INwwemMPOiPPo540MdnhCii513\n3oVNyQJg+fK3WblyOS5XA9XVxxkwILvN7WJiYpk8+VwATjttFI899o+gxBtskjDaMGxgCn+6aQIf\nbSjkzY9386dn1nLB+H5cdW4OcdGOUIcnRI8wedSJtYBQ3yAXG9ucLDZuXM+SJa/z738/g9OZxrJl\ny1i69I02t4uMbP5csNlsuFzt94F0V5IwTsJus3HB+P5MHJ7Bmx/vZtXX+1m95RDXTs3l3NFZ2GzS\nTCVEdxcbG0dVVSWxsbEnrKuoqCAuLp6kpCTq6up4552lIYgwvEjC6EB8jIMbvqOYOjaLRe9tZ8Fy\nzYfrC5l5cR55/QNzu70QIjSuu+56fvnL24iKiiYzs2Vt58wzz2blyneZMeMakpOTGTNmHFu2fBui\nSMOD4QlED1PoDALyS0oqOzUnvNOZQHFxheXyHo+HtdsO8/IHOymtqOXM0zKYdt4QUhKi/P7dgYwr\nWCQu/4RrXBCa2A4e3EvfvgPbLRPqJqmT6c5xtXXebTaDtLR4gBxgj+XfZ6WQUmoosABIA0qAWVrr\nHa3K2IFHgUvxTkX5sNb6aXPdTcCvATfeZ8k+pbV+1GfbHwL3AIa57UVa60NWDyJYDMNg4vAMxgxO\n553Ve1n+ZQHrtx/hirMHcsmEbBwRvfa2FiFEL2D1E+4JYK7WeigwF5jXRpnrgSFAHnAWMEcpNchc\n9zowRms9FjgbuEspNRpAKXUGMAe4WGs9EjgHKOvU0QRJVKSda6bk8sAtkxgxKIXXP9rNPU9/yYad\nR+jmNTYhhDipDhOGUqoPMB5YbC5aDIxXSjlbFZ2Ot+bg1loXA0uAaQBa63KtdeMnaSzgoHlC/F8D\nf9VaHzTLlmmtu8Xt1n2SY/jFtaP5zfQx2O0Gj762iX+8uomikqpQhyaEEAFnpUlqAHBAa+0C0Fq7\nlFKF5vJin3LZwF6f9wVmGQCUUlcCDwGDgT9orTebq0YA+Uqpj4F44A3gQZ8E0yGzLa5TnM6ETm/b\n6HxnAueens07n+WzaMU2Zs9fw5VTBnPdxUOJ7eQw3EDE1RUkLv+Ea1wQ/NgOH7YRYaHZ1kqZUOiu\ncdlstoD9XwdtlJTWeimwVCmVDSxRSi3TWmu8fRqjgYuBSGA53mSz0Oq+g9Xp3ZGzh/dhZHYyr3+0\niyUf7mTV2gKmnTeYs0b2xebH3eLh2lkqcfknXOOC0MTmdrs77KDtzp3LoWAlLrfbfcL/tU+nt1+s\npMx9QD+zU7uxczvLXO6rAPDtis9uowxa6wJgDXCFz3avaa1rtdYVwP8CE/05iHCSGBfJTZcP548/\nPgNnUjTz39nKn5//ivyi8lCHJoQQp6TDhKG1PgxsAGaYi2YA681+Cl+vArcopWxm/8bVwGsASqnh\njYWUUunA+UBjk9Qi4BKllKGUcgAXAhs7f0jhISczkT/ccDo/+e5wSspquH/BOp55ZytlVXWhDk0I\nITrFaqPcbcAvlFLbgV+Y71FKLTNHOQE8D+wGdgCrgfu01vnmuluVUt8qpTYAq4DHtNYrzXUvAYeB\nLXgT07fA/FM7rPBgMwwmj8rkz7eeyWWTsvni24Pc/eQXrFhTQIMr/Kq3Qoj2/fznt/LZZ58A8PTT\nT7Bq1co2y82fP8/SfFLLlr1FQUFz1++nn37E3Ln/DEywXcBSH4bWehswqY3ll/u8dgG3n2T7X7ez\nbzfwG/NfjxQTFcG084dw7pgsFr+/g5c/2MnHGwuZcVEeI3PSQh2eEKITfvrT2055H8uWvUVSUjLZ\n2d7W/HPOmco550w95f12FZkaJIj6psby6x+OYePOIyxetYP/eXkj4/LSmX5hHn2SYzregRA9SP32\nz6jXH7dYZhhGQO5lcqgpOIZObrfMc889TXl5Gb/85V0AlJUdY+bMa/mv/7qXBQvmU1dXi8vlYtas\nm7n00stO2P7BB+cwbNhwrr12OpWVlTz88H3s3r2L1NQ0MjIySEnxfhlct24NTz317xb7u+ii7/DO\nO0vReiv/+Mdfeeqpf3PHHb+iuPgwn3/+CQ888BcAXnjhOVasWAbA8OGnceed/5fY2Fjmz59nPrej\nigMH9tOvX3/uv/+/iY6OPuVz157wHCfWw40Zks79P5nEtPMGs2VvKX986kte/2gXNXU9c4ZLIcLR\npZdewapVK5uervfee8uZPHkKI0eO5vHHn+bZZxfxj388zty5/6S8vP1BK88++xSxsXEsWvQ6Dzzw\nF9av/7pp3dChw9rc33e/eyVKDefOO3/Lc88tYsKElo04X3zxGStWLOOJJ55h4cKXcblcPPfc003r\ntd7Kfff9mRdffI2GhgZWrnw3gGenbVLDCBFHhI3LzhzImaf15bUPd/HOF3v5/JuDTDt/MFdMkWdv\niJ7PMXTyCbWAYA5f7du3L4MGDWb16s8455ypLFv2Nr/85W84dqyUhx66j/37C7DbIygvL6OgYA/D\nho086b7Wr1/HnXf+XwCSk5OZOvWCpnVt728vI0eOaje+devWcOGFlxAX5/08uPLKa/jnP//atH7i\nxDNJSEigocHNiBEjOXBg/6mcDkukhhFiKQlR3PK9Edz9o9NJjIvkyaVb+P3cT9l7MDzH7wvRk1x+\n+RW8++7b7Nq1k6qqSsaMGcff/vYw48adzsKFL/Pcc4twOjOore386Ma29ldXV3vKsUdGNk966n0G\nh+uU99kRSRhhYkj/JO6ZdQY3XjaM/Ycrue+5tSxcvo2KahmGK0RXmTr1AjZuXM9LL73AZZddgWEY\nVFRUkJmZiWEYrF27mgMHTrid7ATjx09g2bK3AG9fyMcf/6dpXXv7i4vzPo+jLWecMZEPPniP6uoq\nPB4Pb7+95IRmq2CTJqkwYrMZTBmTxXcm5/LMks2s+mo/a7Ye5vtTcjlvXBZ2m+R3IQIpOjrabI56\ni1de8T4g6fbbf87f/vbfzJ//JMOHj2Dw4LwO93PjjT/loYfuZebMa0lNTWPs2HFN69rb35VXXsNj\nj/2dRYue5447ftVin2edNZldu3bws5/dBMCwYSP48Y9/EojD7jR5HkYYTt3QGNeBI1Usem87W/eW\n0s8Zx8yLhjJ8YErI4wo3Epf/5HkY/unOcQXyeRjylTWM9UuP47fXjeWO74+its7FI4vX8/iSbzhS\ndjzUoQkheiFpkgpzhmFwunIyKjeV5WsKWPbFXjbtPMLlZw7k0knZRDrsoQ5RCNFLSMLoJiIddq6c\nnMPkkZm8+uFOlnyazyebiph+wRBOV04MP2bDFSJUPB6PXKtBFOguB2mS6mbSkqK57aqR/G7mOGKi\nInh8yTf89aUN7C9ue6SFEOHCZrPjcsnNqcHkcjVgswWuFUISRjelslP4001n8KNLhlJwqII5z6zl\nxfe2U1VTH+rQhGhTTEw8FRXH8HjCr/O4J/J43FRUlBITE7gbgaVJqhuz22xcML4/E4dn8OYnu/ng\n6/18ueUQ10zNZcroLGw2qfqL8BEfn0RpaTGHDu2n+QnNLdlsNtzu8Eso3TMug8jIaOLjkwL2+yRh\n9ADxMQ5uuEQxdUwWi97fwcLlmg/XH+D6i4eS1z851OEJAXgHcKSm9mm3TLgORZa4vKRJqgfJzkjg\ndzPHcdtVp1FRXc9DL3zNk299S2nFqU9DIIQQUsPoYQzDYOLwDMYMTued1XtZ/mUB67cf4YqzB3LJ\nhGwcYfogeyFE+JOE0UNFRdq5Zkou54zO5JUPdvL6R7v5ZGMR112Yx5ghaTK0UQjhN/m62cP1SY7h\n59eM4q7pY7HbDR59fRN/f3UjRSVVoQ5NCNHNSMLoJU7LSeXemydy3YV57DpQxuz5a3jlg50cr5Vx\n8UIIa6RJqheJsNu4ZMIAzhyRwRsf72LFmgI+//YgP5g6mLNH9cUmzVRCiHZIDaMXSoyL5MbLhvPH\nH5+BMymaZ5Zt5cGFX7G7sP3HUAohejdJGL1YTmYif7jhdH56xXCOltfwwMJ1PPPOVsqq5KFNQogT\nSZNUL2czDM4emcm4PCdvf76HlWv38dX2w3zv7BwuOqM/EXb5TiGE8LKUMJRSQ4EFQBpQAszSWu9o\nVcYOPApcive+/4e11k+b624Cfg24ATvwlNb60VbbK2A98LjW+renclDCfzFREUw7fwjnjsnipVU7\neOU/O/l4YyEzL8pjZG5aqMMTQoQBq18fnwDmaq2HAnOBeW2UuR4YAuQBZwFzlFKDzHWvA2O01mOB\ns4G7lFKjGzc0k808YElnDkIETt/UWO6cNoZf/WA0Ho+H/3llI4++tonDpdWhDk0IEWIdJgylVB9g\nPLDYXLQYGK+UcrYqOh1vzcGttS7G++E/DUBrXa61bpxtLBZw0HL2sd8DbwPbO3sgIrDGDEnnvp9M\nYtp5g9laUMofn/6Shcu2UFMnw3CF6K2s1DAGAAe01i4A82ehudxXNrDX532Bbxml1JVKqW/NMo9o\nrTeby8cA3wH+3tmDEF3DEWHjsjMH8udbzmTCsAxeXbWDu59czepvDwb8wSxCiPAXtE5vrfVSYKlS\nKhtYopRaBuwGngRu0lq7vN0Y/jMfZt4pTmdCp7ftSuEUl9OZwN256Wzbc5R5b27iybe28Ok3B7n1\n6lEMDpPZcMPpfPkK17ggfGOTuPwTzLisJIx9QD+llN38ULcDWeZyXwXAQGCt+b51jQMArXWBUmoN\ncAXwKjAYWGYmi2TAUEolaq1vtXoQJSWVuN3+f+OVKYv9M2xQKr+/fjyfbiri9Y928eu/f8TUsVl8\nf0ouCbGRIYsrXM9XuMYF4RubxOWfzsZlsxmd+qLdYcLQWh9WSm0AZgAvmD/Xm/0Uvl4FblFKvYF3\nNNXVwLkASqnhWuut5ut04HzgDa11AZDeuAOl1BwgXkZJhS+bYTBlTBZnKCf/++keVn21nzVbD/P9\nKbmcNy4Lu02G4QrRU1ltkroNWKCUmg2UArMAzGal2VrrdcDzwCSgcbjtfVrrfPP1rUqpS4B6wAAe\n01qvDNAxiBCIjXYw46I8pozNYvH723nxve18uOEAMy/MY/ig1FCHJ4ToAkY377wcBORLk1RwnCwu\nj8fD+h1HeGnVDo6U1XCGcvLDC4aQnhQT0rhCLVzjgvCNTeLyTwCapHKAPVa3kzu9xSkzDIPxQ52M\nzEllxZoC3vliLxt3lXDZpGwuO3MgUQ57qEMUQgSAJAwRMJEOO9+bnMPkUZm88p+dLP1sD59tLmL6\nBXmcrpzy0CYhujnpoRQBl5oYzW1XjeR3M8cRE+Xg8SXf8Mji9ewvrgx1aEKIUyAJQ3QZlZ3Cn246\ngxsuGcq+w5XMeWYtL763naqa+lCHJoToBGmSEl3KbrNx/vj+TBiewZuf7OaDr/fz5ZZDXDM1lymj\ns7DZpJlKiO5CahgiKOJjHNxwieJPN04gKz2Ohcs19y1Yy479x0IdmhDCIkkYIqiyMxL43cxx3HbV\naVRU1/PQC1/z5NJvKa2oDXVoQogOSJOUCDrDMJg4PIMxg9NZtnov735ZwPodR7ji7IFcMmEAjggZ\nhitEOJKEIUImKtLO96fkcs7oTF7+YCevf7SbTzYWMf3CIYwdki7DcIUIM9IkJULOmRzDz68ZxV3X\njcVuN/jX65v5+ysbKSqpCnVoQggfkjBE2DhtUCr33jyRGRfmsauwnNnz1/DyBzs4XisPbRIiHEiT\nlAgrEXYbF08YwKQRGbzx8S5WrtnHF98e4tqpuUwelYlNmqmECBmpYYiwlBgXyY2XDeePPz4DZ3I0\nzy7bxoMLv2JXYVmoQxOi15KEIcJaTmYif/jR6fz0iuEcrajhwYVfMf+dLZRVyjBcIYJNmqRE2LMZ\nBmePzGRcnpO3v9jDyjX7+EoXc+XkHC46o3+owxOi15CEIbqNmKgIpp03hCmjs1i8agev/GcnH28s\n5LZrR5OdFhvq8ITo8aRJSnQ7Gamx3DltDHdOG43H42HOU6t59LVNHCqtDnVoQvRoUsMQ3dbowemM\nGJTKF1sPs2il5p6nv+Q7E7P57lkDiY6US1uIQJO/KtGtRdhtXHN+HqMGpfDah7t454u9fLa5iB+e\nP4RJIzLkbnEhAkiapESPkBwfxU+vGMHdN5xOUnwUT761hYde/Jq9B8PvOcxCdFeSMESPMqRfEvf8\n+AxuvGwYh45Wc99za1mwfBvl1XWhDk2Ibk+apESPYzMMpozJ4gzlZOlne1j11X7Wbj3M1efmcP74\nftht8j1JiM6QvxzRY8VGO7juwjzm3DyRQZkJLHp/B3OeWcvWPUdDHZoQ3ZIkDNHj9UuP467pY/n5\nNaOorXfxyEsbmPvmZo4cOx7q0IToViw1SSmlhgILgDSgBJiltd7RqowdeBS4FPAAD2utnzbX3QT8\nGnADduAprfWj5rp7gOsAF1AP3K21XnHqhyZEM8MwGD/UyajcVJav2cc7X+xh064SLpuUzWVnDiTK\nIQ9tEqIjVmsYTwBztdZDgbnAvDbKXA8MAfKAs4A5SqlB5rrXgTFa67HA2cBdSqnR5ro1wASt9Wjg\nZuBlpVRMZw5GiI44Iux87+xB/PmWMxmXl87Sz/bwx6dWs27bYTweT6jDEyKsdZgwlFJ9gPHAYnPR\nYmC8UsrZquh0vDUHt9a6GFgCTAPQWpdrrRv/GmMBB95aCFrrFVrrxlt0NwEG3pqMEF0mNTGa264a\nye9mjiM22sHjS77hkcXr2X+4MtShCRG2rNQwBgAHtNYuAPNnobncVzaw1+d9gW8ZpdSVSqlvzTKP\naK03t/G7ZgG7tNb7rR+CEJ2nslP4040TuOE7in2HK5nz7FpeXLmdyuP1oQ5NiLATtGG1WuulwFKl\nVDawRCm1TGutG9crpaYC9wMX+7vvtLT4TsfldCZ0etuuJHH551Tj+uEliVx2Ti4vLt/Gu5/ns2bb\nYW64fDiXTBqI3db5u8XD9XxB+MYmcfknmHFZSRj7gH5KKbvW2mV2bmeZy30VAAOBteb71jUOALTW\nBUqpNcAVgAZQSp0FvABc5ZtErCopqcTt9r/92elMoLg4/O4Elrj8E8i4rj03h4nKyaL3tvP4axt5\n++NdzLx4KEMHJIc0rkAL19gkLv90Ni6bzejUF+0Om6S01oeBDcAMc9EMYL3ZT+HrVeAWpZTN7N+4\nGngNQCk1vLGQUiodOB/YbL6fALwM/EBr/bXfRyBEgA3oE8//mzmO2646jcqaeh5+8WvmLf2Wo+U1\noQ5NiJCy2iR1G7BAKTUbKMXb14BSahkwW2u9DngemAQ0Dre9T2udb76+VSl1Cd5hswbwmNZ6pbnu\ncSAGmKeUavx9N5ykj0OIoDAMg4nDMxgzJJ13V+9l2eoC1u8o5oqzBvGdiQNwRMgwXNH7GN18KOEg\nIF+apIKjN8dVfOw4r3ywk6+2F+NMjua6C/MYOyS93dlww/V8QfjGJnH5JwBNUjnAHsvb+f2bhOiF\nnMkx3HHNKO66biyOCDv/en0zf39lI0UlVaEOTYigkYQhhB9OG5TKnJsmMOPCPHYVljN7/hpeWrWD\n6pqGUIcmRJeT2WqF8FOE3cbFEwYw6bQM3vhoN++t3cfqbw9y7XmDmTwqE5s8tEn0UFLDEKKTEmMj\nufGyYdxz4xk4U2J4dtk2Hly4jl2FZaEOTYguIQlDiFM0qG8id//odG65YgRHK2p5cOFXzH97C6Uy\nDFf0MNIkJUQAGIbBWSP7MjYvnXe+2MuKNQWs2/4+uZmJ5GYlkpuZSE5WIsnxUaEOVYhOk4QhRADF\nREXwg/MGc+7oTD799hDf7DzC8i8LcJnDvlMSopoTSGYiA/smEBMlf4aie5ArVYgukJEay23XjKa4\nuIK6ehcFhyvZXVhOflE5+YXlfGVOlGAYkJUeR05mcxLp54wjwi6txSL8SMIQootFOuwM6ZfEkH5J\nTcsqj9c3J5CicjbsOMKnm4q85SNsZPdNaGrOyslMJD0put2bBIUIBkkYQoRAfIyD0YPTGD3Y++gX\nj8dDcVkN+WYS2V1Yzn/WH2Dl2n1N5X37QnIyE4mPcYTyEEQvJAlDiDBgGAZ9kmPokxzDpBEZADS4\n3BwormpKIPlF5WzeVULjJDh9kmOaaiA5WYkMzIiXOa5El5KEIUSYirDbGNg3gYF9EzhvXD8Ajtc2\nsPdgBbvNvhC97xirtxwCwG4z6N8nvqkvJDcrkb5psXIjoQgYSRhCdCMxUREMG5jCsIEpTctKK2qb\n+kJ2F5azestB/rP+gFnezqC+zX0hOZmJpCTI0F7ROZIwhOjmUhKiSElwMn6oEwC3x8PBkmpvAjGT\nSOuhvcMGpdIvLZaczEQGydBeYZFcJUL0MDbDICs9jqz0OCaPygSgvsFFwaHmob17isr5YrN3VJZB\n89DeHLNjXYb2irZIwhCiF3BE2BncL4nB5tBepzOB/IKjTfeF7C4qZ8POI3xqJhFHhI2BGQlNfSE5\nWYk4ZWhvrycJQ4heKj7GwajcNEblNg/tPVJW02JU1kcbDvDeuuahvTmZvv0hCSTERobyEESQScIQ\nQgDeob3O5BicyTFMHN48tLfwSFVTX0h+UTnffNo8tNeZHE1uVlLTnerZGfFEOmRob08lCUMIcVIR\ndhvZGQlkZyRw3tjmob0FhyrYbTZl7dh/jC99h/Y6482bCxPIzUoiMzUWm02asnoCSRhCCL/EREWg\nslNQ2c1De49V1jb1heQXlfPlloN8aA7tjY60M6hvgtmhnkRulgzt7a4kYQghTllyfBTjhjoZ5zO0\n99DR6qZmrN2F5axcsw+Xu8AsH2k2ZXnnzBqUmShDe7sB+R8SQgSczTDITIsjM63V0N5Ws/Z+vd2c\ntRfITI9jeE4qWSkx5GYlydDeMCQJQwgRFI4IO4Ozkhic1XLW3j3mDYb5heWs23qIsso6s7yN7Iz4\nppFZuZmJOJNjZGhvCEnCEEKETHyMg5G5aYw0h/amp8ezbWdxU1/I7sJyPt5QyPvr9gMQFx3RdHNh\nbpa3KStRhvYGjaWEoZQaCiwA0oASYJbWekerMnbgUeBSwAM8rLV+2lx3E/BrwA3Ygae01o92tJ0Q\noncxDIP05BjSfYb2utwnztr7Vv4ePObYXmdydPMDqLISGZiRIEN7u4jVGsYTwFyt9QtKqR8B84AL\nWpW5HhgC5OFNLOuVUu9rrfcArwPPaa09SqkE4Bul1Ida600dbCeE6OXstuahvVPNob01dS1n7d11\noIw1Ww8D3v6T/n3iWszam5kWJ0N7A6DDhKGU6gOMBy42Fy0GHlNKObU2nzPpNR1vzcENFCullgDT\ngEe01uU+5WIBBzTd+3PS7U7huIQQPVh05IlDe8sqa5uasvILy/ly62E+3FAIQFSknZymob3Ns/ZK\nf4h/rNQwBgAHtNYuAK21SylVaC73TRjZwF6f9wVmGQCUUlcCDwGDgT9orTdb2U4IIaxIio9iXJ6T\ncXkth/Z6E0gFu4vKzKG9HrN8ZIvH4A7qm0hstHTrtidoZ0drvRRYqpTKBpYopZZprXUg9p2WFt/p\nbZ3OhECEEHASl38kLv+Fa2yBjCujTyKjh/Vtel/f4CK/sJztBaXoglJ2FJSyfscRAAwD+veJJ29A\nCkPN2svAzEQcEbaAxxVIwYzLSsLYB/RTStnN2oUdyDKX+yoABgJrzfetaw4AaK0LlFJrgCsAbXW7\n9pSUVOJ2ezou2IrTmUBxcYXf23U1ics/Epf/wjW2YMSVEhPBJOVkkvLWRKpq6puasfKLKli35SAf\nmBMuRthtDMyIZ8TgdDKTo8mmViJhAAATUklEQVTJSqRPGA3t7ez5stmMTn3R7jBhaK0PK6U2ADOA\nF8yf61v1XwC8CtyilHoDb+f11cC5AEqp4VrrrebrdOB84I2OthNCiK4WF+1gZE4aI3OaZ+0tKa8h\nv6jCO91JYRkrv9xLbZ3LLB/RctberN4ztNdqk9RtwAKl1GygFJgFoJRaBszWWq8DngcmAY3Dbe/T\nWuebr29VSl0C1OO9qfMxrfVKc1172wkhRFAZhkF6UgzpSTFMGNYHgNTUODZuO2QO7S1jd2EFb33e\nPLQ3PSm6xWNwB/ZNIKoHDu01PB7/m3LCyCAgX5qkgkPi8k+4xgXhG1t3iqu2zsVen1l78wvLKSmv\nAcyhvc44c9Zeb20kqwuG9gagSSoH2GN1OxkSIIQQnRAVaWfogGSGDkhuWlZWVddi1t61Ww/zUePQ\nXod31t5cnyTS3Yb2SsIQQogASYqLZGxeOmPz0gHv0N7DpcebksjuwnLeW7ePBpenqbxvX0hO3wRi\nox2hPIR2ScIQQoguYjMM+qbG0jc1lrNGeof31je42V/snbW3caqTxqG9AJlpsU19IblZiQzoEx82\ns/ZKwhBCiCByRNiaEsKFp3uXVdfUk1/UPNXJN/lH+fybgwBE2A2yMxJazNrbJyU0Q3slYQghRIjF\nRjs4LSeV03JSAe/Q3qPltd5RWWYS+XRTEau+ap61NzcriTtnjieYaUMShhBChBnDMEhLiiYtKZoz\nzKG9LreboiPVTR3qh45Wc7y2gVh78FKGJAwhhOgG7DYb/fvE079PPFPGZAHBH4YcHj0pQgghwp4k\nDCGEEJZIwhBCCGGJJAwhhBCWSMIQQghhiSQMIYQQlkjCEEIIYYkkDCGEEJZIwhBCCGGJJAwhhBCW\nSMIQQghhiSQMIYQQlkjCEEIIYYkkDCGEEJZIwhBCCGGJJAwhhBCWSMIQQghhiaUn7imlhgILgDSg\nBJiltd7RqowdeBS4FPAAD2utnzbX3QNcB7iAeuBurfUKn30/CSQDUcDLWus5p3xkQgghAspqDeMJ\nYK7WeigwF5jXRpnrgSFAHnAWMEcpNchctwaYoLUeDdwMvKyUijHX/QV4TWs9FpgA3KSUmtiZgxFC\nCNF1OkwYSqk+wHhgsbloMTBeKeVsVXQ68JTW2q21LgaWANMAtNYrtNbVZrlNgIG3tgLe2kiS+TrW\nfH+4c4cjhBCiq1ipYQwADmitXQDmz0Jzua9sYK/P+4I2ygDMAnZprfeb7+8EpiulDgB7gEe01nus\nHoAQQojgsNSHEShKqanA/cDFPot/BjyvtX5EKZUJfKiUWqe1/tLqftPS4jsdk9OZ0Oltu5LE5R+J\ny3/hGpvE5Z9gxmUlYewD+iml7Fprl9m5nWUu91UADATWmu9b1DiUUmcBLwBXaa21z3a/BHIBtNZF\nSqkPgCmA5YRRUlKJ2+2xWryJ05lAcXGF39t1NYnLPxKX/8I1NonLP52Ny2YzOvVFu8MmKa31YWAD\nMMNcNANYb/ZT+HoVuEUpZTP7N64GXgNQSk0AXgZ+oLX+utV2+XhHVqGUSgDOBb7x+0iEEEJ0KatN\nUrcBC5RSs4FSvP0QKKWWAbO11uuA54FJQONw2/u01vnm68eBGGCeUqpxnzdorTcDNwL/UkrdBTiA\nl7TW757SUQkhhAg4SwlDa70NbzJovfxyn9cu4PaTbD+hnX1/BZxtJQ4hhBChI3d6CyGEsEQShhBC\nCEskYQghhLBEEoYQQghLJGEIIYSwRBKGEEIISyRhCCGEsEQShhBCCEskYQghhLBEEoYQQghLJGEI\nIYSwRBKGEEIISyRhCCGEsEQShhBCCEskYQghhLBEEoYQQghLJGEIIYSwRBKGEEIISyRhCCGEsEQS\nhhBCCEskYQghhLBEEoYQQghLJGEIIYSwRBKGEEIISyKsFFJKDQUWAGlACTBLa72jVRk78ChwKeAB\nHtZaP22uuwe4DnAB9cDdWusVPtv+ArjDXOfSWo89xePqkMdVT3X+RlzHbRhxyRgxiRiG5E8hhDgZ\nSwkDeAKYq7V+QSn1I2AecEGrMtcDQ4A8vIllvVLqfa31HmAN8DetdbVSagzwkVIqU2t9XCl1DTAN\nmKC1rlBKZQTguDrUULCJg+/9q3mBYceITcKIS8EWl9LipxHr8zoiMhjhCSFE2OkwYSil+gDjgYvN\nRYuBx5RSTq11sU/R6cBTWms3UKyUWoI3ETziW5sANgEG3qSyH7gLuEdrXQGgtT50isdkScSg8fT7\nySOU7CvAU1WKp+oY7qpSPNWluEsP4N7/DdTXnLhhVBy22BSMuGQziaSaySUZI9ZMKtEJGIYRjMMQ\nQoigsVLDGAAc0Fq7ALTWLqVUobncN2FkA3t93heYZVqbBezSWu83348AzlRKPQBEAvO01k/5dxj+\nMwyDqL65OOzOk5bx1B33JpHGRNL4uqoUd/UxGkr24TlejrcFzoctwptQGhOIb20lLqUp4Rh2R9ce\npBBCBJDVJqmAUEpNBe6nubYCYMebWM4B0oHPlFJaa/2x1f2mpcV3OianM6GdtQlAn3a397gacFUd\no6HiKA0VJbgqjtJQcdT8WUJDaQENBRvwNNSdsK0tNpGI+FQiEtOwJ6QSkZCKPSGV6vI0kszXtuj4\nsKqttH++Qkfi8l+4xiZx+SeYcVlJGPuAfkopu1m7sANZ5nJfBcBAYK35vkWNQyl1FvACcJXWWrfa\nbrHZlHVYKfUeMBGwnDBKSipxuz0dF2zF6UyguLjC7+1OFAWRmZCW6W1ow9vm5jD/eTweqKtuVUPx\n/nRVldJQWoxn/3Y8NW3EYo/0af5q2Z/SvCwJw9b1uT9w5yuwJC7/hWtsEpd/OhuXzWZ06ot2h58y\nWuvDSqkNwAy8H/gzgPWt+i8AXgVuUUq9gfdj82rgXACl1ATgZeAHWuuvW223CO/Iqo+VUnHmNm/6\nfSRhzDAMiIrDHhUHqf1PWs7jqsdTfYwkRx1HDxxoTiyVR/FUH8N1aBeeqlJwN7T+DRgxCRhxqT5J\nJLllM1hcKkZkTNceqBCiR7P6tfQ2YIFSajZQircfAqXUMmC21nod8DwwCWgcbnuf1jrffP04EAPM\nU0o17vMGrfVm4O/Ak0qpb83lC7XW753CMXVbht2BkeAk2pmAI7pfm2U8Hg+e2srmmkqrWou7ohj3\nwe1QW3Xixo5obLHJLftVYlvVVmKSMGwyvFgIcSJLCUNrvQ1vMmi9/HKf1y7g9pNsP6GdfR8HbrAS\nh/DWVozoBIhOgLTsk5bzNNThqT7mk1CONr12Vx/DXaRpqDoGHlerX2DzNnE1NX0lN3XUH6/qh7s+\n2ptYHFFdfKRCiHAT1E5vETxGRCRGYh9siSfvtPd43HiOV+CpbllbafpZVoS7cAvUHQegyHfjyJg2\nayi22BSMeHN5TILcDClEDyIJoxczzNoEsUmQPuik5Tz1NXiqjpHoqKH0wIGmDvvGe1fcxwppqD4G\nntbDi+0YsY01lGSfxJLq0ySWLDdDCtFNSMIQHTIc0RjJfYlxJlAZN6jNMh63G8/xspb9Kj73rriP\n7m//ZsgW96iceO+KERVew4uF6I0kYYiAMGw2jLgUiEvB3k45782QR1t22lcfa3rdcKSg7Zsh7RHN\n/SpNtRVvTaWmph/u+khvM5hdLmkhuor8dYmgMiJjsEf2g5S2R4EBeNwNeKrLTuxXabx35chePHvX\ng6segELf/UcnnFBDaV1rITJWaitCdIIkDBF2DFsERnwaxKedtLbi8Xigtgp3dSmJEbWUFh7AU3Ws\nxU2RDYd3t3MzZFs3QCa3eG3Y2qsrCdH7SMIQ3ZJhGBAdjz06nlhnAlWJQ9os53HVezvnq0tPvHel\n+hiuQzu8w4vbvBkyESM+tf17V+RmSNGLSMIQPZphd2AkOrEltjPJpMeDp6bCp6P+WMubIcs7uBny\nhGlbvAmmpq4frio3hiMKwxENEVHSxyK6Nbl6Ra9nGN7aBDGJeKdDa5unobbFNPit+1jchVtpqC5r\nuhmysK2d2OzexOGI9g4ndkR7b4KM8EkqjiifZVHeMq1e44gyl0VDRCTYHdIvI7qcJAwhLDIiojCS\nMrAlnfwZX96bIcvxVB0jwVFL2ZFSPA21UF+Lp74GGuq897XU10JD47Ja7zYVxXjqa83yNeB2nfT3\nnBic7SQJJsonwUQ3LTuWnERdLS2SVVMCayzviJZEJFqQhCFEAHlvhkyG2GTinAlUJ3d+hlOPq6Ep\nqTQnnVpoqMFTXwfmck99bdNrzITTlJxqKvE0lHgTkZmccDVw1PoR+SSdaAxHJEZEdMtE1GbNyGdZ\n07a+6xwyC0A3JAlDiDBl2CO8959ExQV0vx63i/QkB8UHS8wEY9Z4fGo3vjUdT0PdiQmprtrbz+Ob\nyFwnPvOlXREnNr01xMZR77G3XVtqTDa+SSgisuWyiCiZPLMLScIQopcxbHZs0XHY4twB3a/H7fbW\niHya4JqSjU9zHGatyDc5NS5z19XgPl7VYhkNtf4FYo/0aY6LBkek2eQW1aq2FHViLaip1hTVXJNy\nROFxxwb0XHVXkjCEEAFh2GwQGXNKQ43beiCQx+OGhvoWyaZFc5xvX1B9q2X1zQnMXVPRoimP+lpO\nmFHgJCrBW9vzSSL4DDowTjZ4wacpj4hoszYU2aI/KRgPPwuU7hOpEKJXMgxb84d0AHk8HnDVt0os\n3lpRy+RUS2ykh6qycrNm1DIReaqO4W5o2Y+Ex4/am83exki4yLab43yb4KLi8aSdG9Bz0hFJGEKI\nXskwDO8HcESk9/Fu7UhxJtBg8VGojYmoaURcQzv9Qz5NbyfUlqrLmmpRjUmt9fNrjqcnQ8Lgzp4C\nv0nCEEKIAGpMREREYkT7/9zs9viOnMPjITY3h6ogPmtcEoYQQnQTXTVyzioZfyaEEMISSRhCCCEs\nkYQhhBDCEkkYQgghLJGEIYQQwhJJGEIIISzp7sNq7QA2W+enXz6VbbuSxOUfict/4RqbxOWfzsTl\ns41fzyE2PB5rc6mEqXOAT0IdhBBCdFPnAp9aLdzdE0YUMAEoAvx42owQQvRqdiATWAtYng64uycM\nIYQQQSKd3kIIISyRhCGEEMISSRhCCCEskYQhhBDCEkkYQgghLJGEIYQQwhJJGEIIISzp7lODtEkp\nNRRYAKQBJcAsrfWOVmXswKPApYAHeFhr/XRH64IQ1z3AdXhvRKwH7tZarzDXPQdcBBwxi7+qtX4w\nSHHNAf4PUGgu+kxrfYe5LhZ4FjgdaAB+q7V+O0hxLQRG+ywaDVyttV7aXsynENNfgWuBQcAorfU3\nbZQJ+rXlR2yhuL6sxDWH4F9fVuIK9vWVBjwPDAbqgB3Az7TWxa3KnfScdNX5gp5bw3gCmKu1HgrM\nBea1UeZ6YAiQB5wFzFFKDbKwrqvjWgNM0FqPBm4GXlZK+T6i/mGt9Vjz3yn/MfsRF8BCn9/t+4fx\nW6Bcaz0E+B7wtFIqEA8z7jAurfWsxpiAHwOlwAoLMXfWEmAKsLedMqG4tqzGForry0pcEPzrq8O4\nQnB9eYC/aK2V1noUsAt4uI1y7Z2TrjpfPS9hKKX6AOOBxeaixcB4pZSzVdHpwFNaa7eZvZcA0yys\n69K4tNYrtNbV5ttNgIH3G3aX8ON8tWc65oe5WQNYB1wWgrh+AryotbY81YG/tNafaq33dVAsqNeW\nP7EF+/qyGlcHAn59dTKuYFxfR7XWH/osWg0MbKNoe+ekS84X9MCEAQwADmitXQDmz0Jzua9sWn6z\nKPAp0966ro7L1yxgl9Z6v8+y3yilNiulliilhp9iTP7GdZ1SapNSaqVS6iyf5SE/X0qpSGAm8IzF\nmLtSsK+tzgrG9eWPYF5ffgnF9aWUsgG3A0vbWB2Sa6wnJoweQSk1FbgfmOGz+L+AIWZV9Q1gudkm\nHgxPADlmU8YjwP+a7a3h4mqgQGu9wWdZuMccMnJ9+S0U19e/gErgsQDu85T0xISxD+jXeKGbP7PM\n5b4KaFnVy/Yp0966ro4L85vKC3g713Tjcq31Aa2123y9EIgH+gcjLq31Qa11vfn6PXP9SHN1SM+X\n6WZaffvrIOauFOxryy9Bvr4sCcH15a+gXl9mh3weML3x/6SVkFxjPS5haK0PAxto/uY0A1jfepQB\n8Cpwi1LKZraLXw28ZmFdl8allJoAvAz8QGv9dat1/XxefwfvSJcDQYrL93ePxTuypPHD5lXgZ+a6\nPLxTzi8PRlzm7+yPd17/F/2IuSsF9dryR7CvLz/iCur15WdsQb2+lFJ/xjvC6ep2+kvaOydddr56\n5LBa4DZggVJqNt5RDbMAlFLLgNla63V4h65NwjtsDeA+rXW++bq9dV0d1+NADDBPKdW43Q1a683m\nthmAGygHrtRaNwQprj8rpU7H+yFSZ8Z00Nz+EeA5pdROc/2tWuuKIMUF3tErb2mtS1tt317MnaKU\nehS4BugLvK+UKtFanxYG15bV2IJ+fVmMK+jXl8W4ILjX12nAH4DtwOfm/1G+1vr7SqkNwOVa60La\nPydd9fcoz8MQQghhTY9rkhJCCNE1JGEIIYSwRBKGEEIISyRhCCGEsEQShhBCCEskYQghhLBEEoYQ\nQghLJGEIIYSw5P8DUmwrxWF5iiAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqP-D8Zi0LiO",
        "colab_type": "text"
      },
      "source": [
        "# Gradually transition to my code\n",
        "To track every changes I commit this code to AnExample repository and move all model and data to the same place\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0-YPriF0oV-",
        "colab_type": "code",
        "outputId": "7da4ef29-9c00-4bb0-b433-b8f02b53e721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!git clone https://github.com/hossein20s/AnExample src/ramtin-duplicate\n",
        "!cd src/ramtin-duplicate/; git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'src/ramtin-duplicate' already exists and is not an empty directory.\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "From https://github.com/hossein20s/AnExample\n",
            "   ac22fed..64bb450  master     -> origin/master\n",
            "Updating ac22fed..64bb450\n",
            "Fast-forward\n",
            " Double_check_Ramtin_code.ipynb | 262 \u001b[32m++++++++++++++++++++++++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " model.3conv1D.yaml             |  97 \u001b[32m+++++++++++++++\u001b[m\n",
            " model.ramtin2lstm64.h5         | Bin \u001b[31m215280\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " 3 files changed, 302 insertions(+), 57 deletions(-)\n",
            " create mode 100644 model.3conv1D.yaml\n",
            " delete mode 100644 model.ramtin2lstm64.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8FU0n4S3YCu",
        "colab_type": "code",
        "outputId": "e676e1aa-c317-4039-934b-38f4feacfeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "import modelutil\n",
        "from modelutil import load_model_yaml\n",
        "\n",
        "model = load_model_yaml(SRC_DIR, model_name, initial_epoch)\n",
        "#model = keras_model()\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load model from file src/ramtin-duplicate//model.3conv1D.yaml\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_7 (Conv1D)            (None, 13, 10)            210       \n",
            "_________________________________________________________________\n",
            "conv1d_8 (Conv1D)            (None, 9, 20)             1020      \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 5, 40)             4040      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 5,471\n",
            "Trainable params: 5,471\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VQBZ8ZTeqES",
        "colab_type": "text"
      },
      "source": [
        "# Input constraints\n",
        "if return_sequences: 3D tensor with shape  (batch_size, timesteps, units).\n",
        "else, 2D tensor with shape (batch_size, units)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWfHJRis69o1",
        "colab_type": "code",
        "outputId": "6c7c2950-3fec-424b-f958-a25129ed50b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "import datautil\n",
        "from datautil import data_reader\n",
        "\n",
        "reader = data_reader(DATA_FILE, columns=columns, label_index=0, window_size=window_size, batchsize=batch_size)\n",
        "data_train, data_label = reader.get_shuff_train_label() \n",
        "print(data_train.shape)\n",
        "print(data_label.shape)\n",
        "#  reader.get_next_train_batch() #reader.get_shuff_train_label()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Data passed should be normalized!\n",
            "reading data from file src/ramtin-duplicate//case01.csv\n",
            "Raw data (7173, 54)\n",
            "Dropna with selected columns (7173, 54)\n",
            "[[72.   1.7]\n",
            " [72.   1.7]\n",
            " [72.   1.7]]\n",
            "(6735, 80, 1)\n",
            "(6735, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_05A6P08tqu",
        "colab_type": "code",
        "outputId": "0aa9d505-ea7a-4625-bf72-ff83172e35e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from modelutil import Callbacks\n",
        "\n",
        "callbacks = Callbacks(model_name, batch_size, epochs)\n",
        "\n",
        "history = model.fit(\n",
        "  data_train,\n",
        "  data_label,\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        "  validation_split = 0.35,\n",
        "  verbose=0,\n",
        "  callbacks=callbacks.getDefaultCallbacks(),\n",
        "  initial_epoch = initial_epoch,\n",
        "  \n",
        ")\n",
        "\n",
        "plt.plot(np.arange(epochs - initial_epoch), history.history['loss'], label='train')\n",
        "plt.plot(np.arange(epochs - initial_epoch), history.history['val_loss'], label='validation')\n",
        "plt.legend()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc35e343390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T5S44fvBoz9",
        "colab_type": "text"
      },
      "source": [
        "# Reconstruct the model \n",
        "I try to go line by line and reconsruct Ramtin code in Keras\n",
        "\n",
        "\n",
        "```\n",
        "Cells = [tf.nn.rnn_cell.BasicLSTMCell(size) for size in self.lstm_size]\n",
        "Cell = tf.nn.rnn_cell.MultiRNNCell(Cells)\n",
        "RNN_input = tf.unstack(self.volume, axis=1)\n",
        "output, state = tf.nn.static_rnn(Cell, RNN_input, dtype=tf.float32)\n",
        "        c, h = state[-1]\n",
        "out = tf.concat([c, h], axis=-1)\n",
        "out = tf.layers.dense(out, 1, activation=None,\\\n",
        "            kernel_initializer=tf.contrib.layers.xavier_initializer(),\\\n",
        "            bias_initializer=tf.zeros_initializer())\n",
        "        self.pred = out\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml3muHS6B2ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTMCell, LSTM, Dense\n",
        "\n",
        "\n",
        "def keras_model():\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(64, return_sequences=True))   #, input_shape=(80, 1), return_sequences=True))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(LSTM(64))\n",
        "  #    model.add(Dropout(0.3))\n",
        "  model.add(Dense(1))\n",
        "  model.build()\n",
        "  return model\n",
        "\n",
        "def keras_model2():\n",
        "  model = Sequential()\n",
        "  model.add(LSTMCell(64))\n",
        "  model.add(LSTMCell(64))\n",
        "  model.add(Dense(1))\n",
        "  model.build()\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K4F6xdbEdXT",
        "colab_type": "text"
      },
      "source": [
        "# Going back where Ramtin fixed the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9QAKUqNEn2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime as dt\n",
        "\n",
        "class Timer():\n",
        "\n",
        "\tdef __init__(self):\n",
        "\t\tself.start_dt = None\n",
        "\n",
        "\tdef start(self):\n",
        "\t\tself.start_dt = dt.datetime.now()\n",
        "\n",
        "\tdef stop(self):\n",
        "\t\tend_dt = dt.datetime.now()\n",
        "\t\tprint('Time taken: %s' % (end_dt - self.start_dt))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JuYeIniEvO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x7NYhKaE0LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "6d26498c-681c-49ce-9525-e8025e25be43"
      },
      "source": [
        "\n",
        "!pip install gcsfs\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "case_id = '01'\n",
        "data = pd.read_csv('http://storage.googleapis.com/medicalblockchain_dev/data/UniversityQueenslandVitalSignals/case%s/uq_vsd_case%s_trenddata.csv'%(case_id, case_id),\\\n",
        "                               error_bad_lines=False, warn_bad_lines=False, index_col=False);\n",
        "data = data[[\"RelativeTimeMilliseconds\", \"NBP (Mean)\", \"Minute Volume\"]].dropna()\n",
        "data = (data - data.mean())/(data.max() - data.min())\n",
        "\n",
        "\n",
        "DATA_FILE = 'case1_trends_3column.csv'\n",
        "\n",
        "data.to_csv(DATA_FILE)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/19/68ab4e6570a7882698058be8ecf1b195b0b784b838ac1b0ea82c422c0f5a/gcsfs-0.2.2.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.0.1)\n",
            "Building wheels for collected packages: gcsfs\n",
            "  Building wheel for gcsfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/0f/b9/5bc5222756d121ccace51ab3084a1c733380908a4e2f939038\n",
            "Successfully built gcsfs\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwxgqAvEE_86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class data_reader():\n",
        "    def __init__(self, filename, l=10, batchsize=32, random=True):\n",
        "        # process the data into a matrix, and return the lenght\n",
        "        print(\"Warning: Data passed should be normalized!\")\n",
        "        self.frac = 0.65\n",
        "        self.random = random\n",
        "        df = pd.read_csv(filename)\n",
        "        self.process(df, l)\n",
        "        self.batchsize = batchsize\n",
        "\n",
        "        self.pointer = 0\n",
        "        self.epoch = 0\n",
        "    def process(self, df, l):\n",
        "        # Generate the data matrix\n",
        "        print(df.head(3))\n",
        "        df = df[[\"NBP (Mean)\", \"Minute Volume\"]].dropna().as_matrix()\n",
        "        length = df.shape[0]\n",
        "        data = np.zeros((length-l, l))\n",
        "        label = np.zeros((length-l, 1))\n",
        "        for counter in range(length-l):\n",
        "            data[counter, :] = df[counter: counter+l, 1]\n",
        "            label[counter, :] = df[counter+l, 0]\n",
        "        # Random shuffle\n",
        "        length = data.shape[0]\n",
        "        idx = np.random.choice(length, length, replace=False)\n",
        "        if not self.random:\n",
        "            idx = np.arange(length)\n",
        "        self.val_idx = idx[int(self.frac*length):]\n",
        "\n",
        "        shuf_data = data[idx, :]\n",
        "        shuf_label = label[idx, :]\n",
        "        self.shuf_data = shuf_data\n",
        "        self.shuf_label = shuf_label\n",
        "        self.data =data\n",
        "        self.label = label\n",
        "\n",
        "        self.train_data = shuf_data[:int(self.frac*length), :]\n",
        "        self.train_label = shuf_label[:int(self.frac*length), :]\n",
        "        self.train_size = int(self.frac*length)\n",
        "\n",
        "        self.val_data = shuf_data[int(self.frac*length):, :]\n",
        "        self.val_label = shuf_label[int(self.frac*length):, :]\n",
        "        self.val_size = int((1-self.frac)*length)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def get_next_train_batch(self):\n",
        "        # getting the next train batch\n",
        "        if self.pointer + self.batchsize >= self.train_size:\n",
        "            end = self.train_size\n",
        "            start = self.pointer\n",
        "            self.pointer = 0\n",
        "            self.epoch += 1\n",
        "        else:\n",
        "            end = self.pointer + self.batchsize\n",
        "            start = self.pointer\n",
        "            self.pointer += self.batchsize\n",
        "        X = np.expand_dims(self.train_data[start:end, :], axis=-1)\n",
        "        Y = self.train_label[start:end, :]\n",
        "        return X, Y\n",
        "\n",
        "    def get_val(self):\n",
        "        X = np.expand_dims(self.val_data, axis=-1)\n",
        "\n",
        "        return X, self.val_label[:]\n",
        "\n",
        "    def get_whole(self):\n",
        "        # get whole, for validation set\n",
        "        X = np.expand_dims(self.data[:, :], axis=-1)\n",
        "        Y = self.label[:, :]\n",
        "        return X, Y\n",
        "\n",
        "    def reset(self):\n",
        "        self.pointer = 0\n",
        "        self.epoch = 0\n",
        "\n",
        "    def get_epoch(self):\n",
        "        # return the current epoch\n",
        "        return self.epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv8IttUzFFaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "da2f212b-1ef3-4e99-8d52-ade175e0771c"
      },
      "source": [
        "import json\n",
        "!wget \"bit.ly/ramtinconfig\" -O config.ramtin.json\n",
        "CONFIG_JSON_FILE = 'config.ramtin.json'\n",
        "import os\n",
        "configs = json.load(open(CONFIG_JSON_FILE, 'r'))\n",
        "\n",
        "'''\n",
        "data = DataLoader(\n",
        "\tos.path.join('data', configs['data']['filename']),\n",
        "\tconfigs['data']['train_test_split'],\n",
        "\tconfigs['data']['columns']\n",
        ")\n",
        "'''\n",
        "array_size = configs['training']['feature_size']\n",
        "reader = data_reader(\n",
        "\tos.path.join( configs['data']['filename']),\n",
        "\tl=array_size,\n",
        "\tbatchsize=configs['training']['batch_size']\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-18 00:56:58--  http://bit.ly/ramtinconfig\n",
            "Resolving bit.ly (bit.ly)... 18.232.107.46, 34.230.11.244, 54.158.109.168, ...\n",
            "Connecting to bit.ly (bit.ly)|18.232.107.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/hossein20s/Average_Blood_Pressure_estimation/master/config.ramtin.json [following]\n",
            "--2019-06-18 00:56:58--  https://raw.githubusercontent.com/hossein20s/Average_Blood_Pressure_estimation/master/config.ramtin.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1153 (1.1K) [text/plain]\n",
            "Saving to: ‘config.ramtin.json’\n",
            "\n",
            "\rconfig.ramtin.json    0%[                    ]       0  --.-KB/s               \rconfig.ramtin.json  100%[===================>]   1.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-18 00:56:58 (154 MB/s) - ‘config.ramtin.json’ saved [1153/1153]\n",
            "\n",
            "Warning: Data passed should be normalized!\n",
            "   Unnamed: 0  RelativeTimeMilliseconds  NBP (Mean)  Minute Volume\n",
            "0           8                 -0.502928    0.668077      -0.426493\n",
            "1           9                 -0.502789    0.668077      -0.426493\n",
            "2          10                 -0.502651    0.668077      -0.426493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ti6nHmNFGhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from numpy import newaxis\n",
        "from keras.layers import Dense, Activation, Dropout, LSTM\n",
        "from keras import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import RepeatVector, Conv1D, MaxPool1D, Flatten\n",
        "\n",
        "class TheModel():\n",
        "  \"\"\"A class for an building and inferencing an lstm model\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.model = Sequential()\n",
        "\n",
        "  def load_model(self, filepath):\n",
        "    print('[Model] Loading model from file %s' % filepath)\n",
        "    self.model = load_model(filepath)\n",
        "\n",
        "  def build_model(self, configs):\n",
        "    timer = Timer()\n",
        "    timer.start()\n",
        "    timer.start()\n",
        "    \n",
        "    input_shape = None\n",
        "    has_input_shape = False\n",
        "    is_first_layer = True\n",
        "\n",
        "\n",
        "\n",
        "    for layer in configs['model']['layers']:\n",
        "      neurons = layer['neurons'] if 'neurons' in layer else None\n",
        "      rate = layer['rate'] if 'rate' in layer else None\n",
        "      activation = layer['activation'] if 'activation' in layer else None\n",
        "      return_seq = layer['return_seq'] if 'return_seq' in layer else None\n",
        "      input_timesteps = layer['input_timesteps'] if 'input_timesteps' in layer else None\n",
        "      input_dim = layer['input_dim'] if 'input_dim' in layer else None\n",
        "      kernel_size = layer['kernel_size'] if 'kernel_size' in layer else None\n",
        "      filters = layer['filters'] if 'filters' in layer else None\n",
        "      strides = layer['strides'] if 'strides' in layer else 1\n",
        "      print(kernel_size)\n",
        "      if 'input_shape' in layer:\n",
        "        input_shape = layer['input_shape']\n",
        "        has_input_shape = true\n",
        "\n",
        "      if layer['type'] == 'dense':\n",
        "        if(is_first_layer):\n",
        "          self.model.add(Dense(neurons, activation=activation, input_shape=input_shape))\n",
        "          is_first_layer = False\n",
        "        else:\n",
        "          self.model.add(Dense(neurons, activation=activation))\n",
        "      if layer['type'] == 'lstm' or layer['type'] == 'conv1D':\n",
        "        input_shape=(input_timesteps, input_dim)\n",
        "        has_input_shape = True\n",
        "        if(layer['type'] == 'lstm'):\n",
        "          if is_first_layer:\n",
        "            self.model.add(LSTM(neurons, input_shape=input_shape, return_sequences=return_seq))\n",
        "            is_first_layer = False\n",
        "          else:\n",
        "            self.model.add(LSTM(neurons, return_sequences=return_seq))\n",
        "        if(layer['type'] == 'conv1D'):\n",
        "          if is_first_layer:\n",
        "            self.model.add(Conv1D(filters, kernel_size, strides=strides, activation='relu', input_shape=input_shape))\n",
        "            is_first_layer = False\n",
        "          else:\n",
        "            self.model.add(Conv1D(filters, kernel_size, strides=strides, activation='relu'))\n",
        "      if layer['type'] == 'dropout':\n",
        "          self.model.add(Dropout(rate))\n",
        "      if layer['type'] == 'flatten':\n",
        "          self.model.add(Flatten())\n",
        "      if layer['type'] == 'maxpool1D':\n",
        "          self.model.add(MaxPool1D(rate))\n",
        "      if layer['type'] == 'repeat_vector':\n",
        "        self.model.add(RepeatVector(input_timesteps))\n",
        "      if layer['type'] == 'time_distributed_dense':\n",
        "        self.model.add(TimeDistributed(Dense(neurons, activation=activation)))\n",
        "      if layer['type'] == 'attention_decoder':\n",
        "        self.model.add(AttentionDecoder(neurons, input_dim))\n",
        "      if layer['type'] == 'attention':\n",
        "        self.model.add(Attention())\n",
        "\n",
        "    print(configs['model']['metrics'])\n",
        "    self.model.compile(loss='mse', \n",
        "                       optimizer=configs['model']['optimizer'],\n",
        "                      metrics=configs['model']['metrics'])\n",
        "    print('[Model] Model Compiled')\n",
        "    print('input_shape: ',input_shape)\n",
        "    if has_input_shape:\n",
        "      self.model.summary()\n",
        "    timer.stop()\n",
        "\n",
        "  def fit(self, x, y, epochs, batch_size, validation_split, save_dir):\n",
        "    timer = Timer()\n",
        "    timer.start()\n",
        "    print('[Model] Training Started')\n",
        "    print('[Model] %s epochs, %s batch size' % (epochs, batch_size))\n",
        "\n",
        "    save_fname = os.path.join(save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "    #modelutil.save_model_yaml('data', self.model, 'old3conv1D', 0)\n",
        "    self.model = modelutil.load_model_yaml('data', 'old3conv1D', 0)\n",
        "    callbacks = [\n",
        "        PrintDot()\n",
        "    #            EarlyStopping(monitor='val_loss', patience=2),\n",
        "    #            ModelCheckpoint(filepath=save_fname, monitor='val_loss', save_best_only=True)\n",
        "    ]\n",
        "    history = self.model.fit(\n",
        "      x,\n",
        "      y,\n",
        "      epochs=epochs,\n",
        "      batch_size=batch_size,\n",
        "      validation_split = validation_split, \n",
        "      verbose=0,\n",
        "      callbacks=callbacks\n",
        "    )\n",
        "    self.model.save(save_fname)\n",
        "\n",
        "    print('[Model] Training Completed. Model saved as %s' % save_fname)\n",
        "    timer.stop()\n",
        "    return history\n",
        "\n",
        "  def fit_generator(self, data_gen, epochs, batch_size, steps_per_epoch, save_dir):\n",
        "    timer = Timer()\n",
        "    timer.start()\n",
        "    print('[Model] Training Started')\n",
        "    print('[Model] %s epochs, %s batch size, %s batches per epoch' % (epochs, batch_size, steps_per_epoch))\n",
        "\n",
        "    save_fname = os.path.join(save_dir, '%s-e%s.h5' % (dt.datetime.now().strftime('%d%m%Y-%H%M%S'), str(epochs)))\n",
        "    callbacks = [\n",
        "      ModelCheckpoint(filepath=save_fname, monitor='loss', save_best_only=True)\n",
        "    ]\n",
        "    self.model.fit_generator(\n",
        "      data_gen,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks,\n",
        "      workers=1\n",
        "    )\n",
        "\n",
        "    print('[Model] Training Completed. Model saved as %s' % save_fname)\n",
        "    timer.stop()\n",
        "\n",
        "  def predict_point_by_point(self, data):\n",
        "    #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
        "    print('[Model] Predicting Point-by-Point...')\n",
        "    predicted = self.model.predict(data)\n",
        "    predicted = np.reshape(predicted, (predicted.size,))\n",
        "    return predicted\n",
        "\n",
        "  def predict_sequences_multiple(self, data, window_size, prediction_len):\n",
        "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
        "    print('[Model] Predicting Sequences Multiple...')\n",
        "    prediction_seqs = []\n",
        "    for i in range(int(len(data)/prediction_len)):\n",
        "      curr_frame = data[i*prediction_len]\n",
        "      predicted = []\n",
        "      for j in range(prediction_len):\n",
        "        predicted.append(self.model.predict(curr_frame[newaxis,:,:])[0,0])\n",
        "        curr_frame = curr_frame[1:]\n",
        "        curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
        "      prediction_seqs.append(predicted)\n",
        "    return prediction_seqs\n",
        "\n",
        "  def predict_sequence_full(self, data, window_size):\n",
        "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
        "    print('[Model] Predicting Sequences Full...')\n",
        "    curr_frame = data[0]\n",
        "    predicted = []\n",
        "    for i in range(len(data)):\n",
        "      predicted.append(self.model.predict(curr_frame[newaxis,:,:])[0,0])\n",
        "      curr_frame = curr_frame[1:]\n",
        "      curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNlyAV3kFRnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "63e716f2-bfcd-4aca-cdef-ae1ab0f61bb4"
      },
      "source": [
        "import json\n",
        "\n",
        "theModel = TheModel()\n",
        "print(configs)\n",
        "theModel.build_model(configs)\n",
        "\n",
        "max_epoch = configs['training']['epochs']\n",
        "\n",
        "epoch = reader.get_epoch()\n",
        "\n",
        "x = np.expand_dims(reader.shuf_data, axis=-1)\n",
        "y = reader.shuf_label\n",
        "history = theModel.fit(\n",
        "  x,\n",
        "  y,\n",
        "  epochs = 3, #max_epoch,\n",
        "  batch_size = configs['training']['batch_size'],\n",
        "  validation_split = configs['training']['validation_split'],\n",
        "  save_dir = configs['model']['save_dir']\n",
        ")\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': {'columns': ['RelativeTimeMilliseconds, NBP (Mean), Minute Volume'], 'filename': 'case1_trends_3column.csv', 'n_features': 1, 'normalise': True, 'sequence_length': 64, 'train_test_split': 0.85}, 'model': {'layers': [{'filters': 10, 'input_dim': 1, 'input_timesteps': 80, 'kernel_size': 20, 'strides': 5, 'type': 'conv1D'}, {'filters': 20, 'kernel_size': 5, 'type': 'conv1D'}, {'filters': 40, 'kernel_size': 5, 'type': 'conv1D'}, {'type': 'flatten'}, {'activation': 'linear', 'neurons': 1, 'type': 'dense'}], 'loss': 'mse', 'metrics': ['mse', 'acc'], 'optimizer': 'adam', 'save_dir': '/tmp'}, 'training': {'batch_size': 64, 'epochs': 500, 'feature_size': 80, 'validation_split': 0.35}}\n",
            "20\n",
            "5\n",
            "5\n",
            "None\n",
            "None\n",
            "['mse', 'acc']\n",
            "[Model] Model Compiled\n",
            "input_shape:  (None, None)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_16 (Conv1D)           (None, 13, 10)            210       \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 9, 20)             1020      \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 5, 40)             4040      \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 5,471\n",
            "Trainable params: 5,471\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Time taken: 0:00:00.140084\n",
            "[Model] Training Started\n",
            "[Model] 3 epochs, 64 batch size\n",
            "load model from file data/model.old3conv1D.yaml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-68a5a3cd0799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0msave_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-7328797404fd>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, batch_size, validation_split, save_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    682\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    }
  ]
}